{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV;\n",
    "using DataFrames;\n",
    "using LinearAlgebra;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size: (846, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[3]:4\n",
      "└ @ Core In[3]:4\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[3]:7\n",
      "└ @ Core In[3]:7\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = (::getfield(Main, Symbol(\"##3#5\")))(::String) at none:0\n",
      "└ @ Main ./none:0\n",
      "┌ Warning: `deletecols!(df::DataFrame, inds)` is deprecated, use `select!(df, Not(inds))` instead.\n",
      "│   caller = top-level scope at In[3]:13\n",
      "└ @ Core In[3]:13\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = top-level scope at In[3]:17\n",
      "└ @ Core ./In[3]:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for training: 700\n",
      "Number of samples for test: 147\n",
      "Input size: 18\n",
      "Number of unique values(labels): 4\n",
      "Classes: Dict(\"opel\" => 4,\"bus\" => 3,\"saab\" => 2,\"van\" => 1)\n"
     ]
    }
   ],
   "source": [
    "# Import vehicle data as dataframe\n",
    "dataframe = DataFrame(CSV.File(\"vehicle.csv\"));\n",
    "println(\"Dataframe size: \", size(dataframe))\n",
    "\n",
    "# Number of classes to identify\n",
    "num_classes = size(unique(dataframe[\"Class\"]),1)\n",
    "\n",
    "# Labels as dict\n",
    "label_dict = Dict([(c, findall(x->x==c,unique(dataframe[\"Class\"]))[1]) for c in unique(dataframe[\"Class\"])])\n",
    "\n",
    "# Create new column, delete classes\n",
    "classes = dataframe[:,end]\n",
    "deletecols!(dataframe, size(dataframe,2))\n",
    "dataframe[!,\"Y\"] = zeros(Int8, size(dataframe,1))\n",
    "\n",
    "for i=1:size(dataframe,1)\n",
    "    dataframe[\"Y\"][i] = label_dict[classes[i]]\n",
    "end\n",
    "\n",
    "# Separate Input data and labels\n",
    "# Training Data\n",
    "x_train = convert(Array, dataframe[: ,[x for x in names(dataframe) if x != \"Y\"]][1:700,:])\n",
    "y_train_ind = convert(Array, dataframe[:, filter(x -> x == \"Y\", names(dataframe))][1:700,:])\n",
    "# Correct the label format\n",
    "y_train = fill(Float64[], (size(x_train,1),1))\n",
    "\n",
    "for i=1:size(y_train_ind,1)\n",
    "    new_y = zeros(Float64, num_classes)\n",
    "    new_y[y_train_ind[i]] = 1.0\n",
    "    y_train[i] = new_y\n",
    "end\n",
    "\n",
    "# Test Data\n",
    "x_test = convert(Array, dataframe[: ,[x for x in names(dataframe) if x != \"Y\"]][700:end,:])\n",
    "y_test_ind = convert(Array, dataframe[:, filter(x -> x == \"Y\", names(dataframe))][700:end,:])\n",
    "# Correct the label format\n",
    "y_test = fill(Float64[], (size(x_train,1),1))\n",
    "for i=1:size(y_test_ind,1)\n",
    "    new_y = zeros(Float64, num_classes)\n",
    "    new_y[y_train_ind[i]] = 1.0\n",
    "    y_test[i] = new_y\n",
    "end\n",
    "\n",
    "# Normalize Data\n",
    "x_train = x_train ./ maximum(x_train, dims=1)\n",
    "x_test  = x_test  ./ maximum(x_test , dims=1)\n",
    "\n",
    "# Display the data\n",
    "println(\"Number of samples for training: \", size(x_train,1))\n",
    "println(\"Number of samples for test: \", size(x_test,1))\n",
    "println(\"Input size: \", size(x_train,2))\n",
    "println(\"Number of unique values(labels): \", size(unique(y_train),1))\n",
    "println(\"Classes: \", label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Layer\n",
    "    weights::Union{Missing, Array{Float64,2}}\n",
    "    biases::Union{Missing, Array{Float64,1}}\n",
    "    z::Array{Float64,2}\n",
    "    a::Array{Float64,2}\n",
    "    activation::String\n",
    "    \n",
    "    function Layer(num_perceptrons::Int64, prev_layer_size::Int64, activation::String)\n",
    "        activation_types = [\"relu\", \"softmax\", \"sigmoid\", \"leaky_relu\", \"none\"]\n",
    "        if (activation != \"none\") && (activation in activation_types)\n",
    "            # The matrix has column vectors for each activation of previous layer\n",
    "            # weights[:,1] is the vector of weights for perceptron 1 \n",
    "            weights = rand(Float64, (prev_layer_size, num_perceptrons))\n",
    "        elseif activation == \"none\"\n",
    "            weights = missing\n",
    "        else \n",
    "            error(\"Activation function: \", activation, \" is not valid.\")\n",
    "        end\n",
    "        \n",
    "        biases = zeros(num_perceptrons)\n",
    "        # Initialize outputs as zeros\n",
    "        z = zeros(num_perceptrons, 1)\n",
    "        a = zeros(num_perceptrons, 1)\n",
    "        new(weights, biases, z, a, activation)\n",
    "    end\n",
    "end\n",
    "\n",
    "struct DeepNeuralNet\n",
    "    input_size::Int64\n",
    "    hidden_layers::Array{Layer,1}\n",
    "    \n",
    "    function DeepNeuralNet(input_size::Int64)\n",
    "        new(input_size, [])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softmax (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activation Functions\n",
    "function relu(z)\n",
    "    r(z) = z < 0 ? 0 : z\n",
    "    return r.(z)\n",
    "end\n",
    "    \n",
    "function softmax(z::Array{Float64,2})\n",
    "    return broadcast(exp, z) ./ sum(broadcast(exp, z))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_layer (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_layer(net::DeepNeuralNet, layer_size::Int64, activation::String)\n",
    "    if length(net.hidden_layers) == 0\n",
    "        new_layer = Layer(layer_size, net.input_size, activation)\n",
    "    else\n",
    "        new_layer = Layer(layer_size, size(net.hidden_layers[end].weights, 2), activation)\n",
    "    end\n",
    "    push!(net.hidden_layers, new_layer)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feed_forward (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function feed_forward(net::DeepNeuralNet, x::Union{Array{Float64,1},Array{Int64,1}})::Array{Float64,2}\n",
    "    num_hidden_layers = length(net.hidden_layers)\n",
    "    layers = net.hidden_layers\n",
    "   \n",
    "    # Make x -> 2 Dimensional\n",
    "    x = reshape(x,(size(x,1),1))\n",
    "    \n",
    "    # All layers from first hidden to output layer\n",
    "    for layer_index=1:num_hidden_layers\n",
    "        activation_func = layers[layer_index].activation\n",
    "        weights = layers[layer_index].weights\n",
    "        biases  = layers[layer_index].biases\n",
    "        \n",
    "        # Input to layer 1 of the network\n",
    "        # use the input values else\n",
    "        # apply the previous layer outputs\n",
    "        if layer_index == 1\n",
    "            layers[layer_index].z = (weights' * x) .+ biases\n",
    "        else \n",
    "            prev_layer_a = layers[layer_index-1].a\n",
    "            layers[layer_index].z = (weights' * prev_layer_a) .+ biases\n",
    "        end\n",
    "        \n",
    "        # Apply activation function \n",
    "        if(activation_func == \"relu\")    \n",
    "            layers[layer_index].a = broadcast(relu, layers[layer_index].z)\n",
    "        elseif(activation_func == \"softmax\")\n",
    "            layers[layer_index].a = softmax(layers[layer_index].z)\n",
    "        end\n",
    "    end\n",
    "    return net.hidden_layers[end].a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "back_propagation (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function back_propagation(net::DeepNeuralNet, pred::Array{Float64,1}, label::Array{Float64,1})\n",
    "    num_layers = size(net.hidden_layers,1)\n",
    "    \n",
    "    for i=reverse(1:num_layers)\n",
    "        \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train(net::DeepNeuralNet, x::Array{Float64,2}, y::Array{Array{Float64,1},2}; epochs::Int64=20)\n",
    "    num_data = size(x,1)\n",
    "    cost_per_epoch::Array{Float64,1} = zeros(Float64, epochs)\n",
    "    \n",
    "    # Needs to change according to new output labels\n",
    "    cross_entropy_loss(preds, label) = -sum(label .* log.(preds))\n",
    "    \n",
    "    for epoch=1:epochs\n",
    "        cost::Float64 = 0.0\n",
    "        # Iterate through the training data\n",
    "        for i=1:num_data\n",
    "            # Predict the output for given data\n",
    "            prediction = feed_forward(net, x[i,:])\n",
    "            # Calculate cost and add\n",
    "            cost = cross_entropy_loss(prediction, y[i])\n",
    "            # Check if output is correct for backprop\n",
    "            is_correct_pred = argmax(prediction)[1] == argmax(y[i])\n",
    "            \n",
    "            # Backprop\n",
    "            back_propagation(net, prediction[:,1], y[i])\n",
    "        end\n",
    "#         cost_for_iters::Float64 = (-1/num_data) * cost\n",
    "#         cost_per_epoch[epoch] = cost_for_iters\n",
    "#         println(\"Epoch: \", epoch, \" Cost: \",  cost_for_iters);\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "num_columns_data = size(x_train,2)\n",
    "num_classes = size(unique(y_train),1)\n",
    "model = DeepNeuralNet(num_columns_data)\n",
    "\n",
    "# Create the layers for the model\n",
    "add_layer(model, 6, \"relu\");\n",
    "add_layer(model, 6, \"relu\");\n",
    "add_layer(model, num_classes, \"softmax\"); # Output Layer\n",
    "\n",
    "train(model, x_train[5:9,:], reshape(y_train[5:9],5,1), epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
